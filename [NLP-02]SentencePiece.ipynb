{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-vision",
   "metadata": {},
   "source": [
    "# SentencePiece project\n",
    "GD 노드 2 \n",
    "\n",
    "프로세스는 다음과 같다.\n",
    "1. 데이터 불러오기 및 전처리\n",
    "2. 데이터 분석\n",
    "3. SentnecPiece 학습\n",
    "4. 모델 성능 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-blowing",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기 및 전처리\n",
    "네이버 영화리뷰 데이터 불러오기 후 중복과 결측치를 제거한다.   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "streaming-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file PosixPath('/home/aiffel-dj28/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc'), line 250 ('font.family:  NanumGothic')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from konlpy.tag import Okt \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-pocket",
   "metadata": {},
   "source": [
    "### 중복, 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "burning-symposium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146182 49157\n"
     ]
    }
   ],
   "source": [
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_data = train_data.dropna(how = 'any') \n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data = test_data.dropna(how = 'any') \n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prospective-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 195339\n",
      "Example:\n",
      ">> 아 더빙.. 진짜 짜증나네요 목소리\n",
      ">> 나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님\n",
      ">> 단순하면서 은은한 매력의 영화\n",
      ">> 보는내내 그대로 들어맞는 예측 카리스마 없는 악역\n",
      ">> 뭐냐..시작하고 3분만에 나왔다. 리플릿 사진 보며 불안하더니만..\n"
     ]
    }
   ],
   "source": [
    "# sampling\n",
    "raw = list(train_data['document']) + list(test_data['document'])\n",
    "print(\"Data Size:\", len(raw))\n",
    "list(map(str, raw))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-lithuania",
   "metadata": {},
   "source": [
    "## 2. 데이터 분석\n",
    "문장의 길이에 따른 분포를 분석하고 각 데이터가 어떻게 생겼는지 살핀다.   \n",
    "그리고 적절한 최대길이로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharp-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data distribution\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    if type(sen) == type(1.0):\n",
    "        print(sen)\n",
    "    sen = str(sen)\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    #sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-conclusion",
   "metadata": {},
   "source": [
    "### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prerequisite-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아\n",
      "잼\n",
      "1\n",
      "4\n",
      "굿\n",
      "짱\n",
      "휴\n",
      ".\n",
      "음\n",
      "?\n",
      "ㅎ\n",
      "ㅋ\n",
      "즐\n",
      "♥\n",
      "굳\n",
      "네\n",
      "ㅇ\n",
      "k\n",
      "ㅠ\n",
      "쒯\n",
      "♬\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 20: return\n",
    "\n",
    "check_sentence_with_length(raw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smaller-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 5\n",
      "Outlier Index: 6\n",
      "Outlier Index: 7\n",
      "Outlier Index: 8\n",
      "Outlier Index: 9\n",
      "Outlier Index: 10\n",
      "Outlier Index: 11\n",
      "Outlier Index: 12\n",
      "Outlier Index: 13\n",
      "Outlier Index: 14\n",
      "Outlier Index: 15\n",
      "Outlier Index: 16\n",
      "Outlier Index: 17\n",
      "Outlier Index: 18\n",
      "Outlier Index: 19\n",
      "Outlier Index: 20\n",
      "Outlier Index: 21\n",
      "Outlier Index: 22\n",
      "Outlier Index: 23\n",
      "Outlier Index: 24\n",
      "Outlier Index: 25\n",
      "Outlier Index: 26\n",
      "Outlier Index: 27\n",
      "Outlier Index: 28\n",
      "Outlier Index: 29\n",
      "Outlier Index: 30\n",
      "Outlier Index: 31\n",
      "Outlier Index: 32\n",
      "Outlier Index: 33\n",
      "Outlier Index: 34\n",
      "Outlier Index: 35\n",
      "Outlier Index: 36\n",
      "Outlier Index: 37\n",
      "Outlier Index: 38\n",
      "Outlier Index: 39\n",
      "Outlier Index: 40\n",
      "Outlier Index: 41\n",
      "Outlier Index: 42\n",
      "Outlier Index: 43\n",
      "Outlier Index: 44\n",
      "Outlier Index: 45\n",
      "Outlier Index: 46\n",
      "Outlier Index: 47\n"
     ]
    }
   ],
   "source": [
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # # 문장 내 단어의 개수가 1500을 초과하는 인덱스를 추출합니다.\n",
    "    if _sum > 1500:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "champion-chrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데너리스 타르 가르엔...나도 용의주인이 되고 싶다...누이랑,근친상간이나 하고 다닐지라도,소설 속에선 제일 멋진 놈이 자이메 라니스터였는데,드라마속에선,드래곤(용)이 제일 멋지네(웃음)감독님 토르-2 다크 월드는 말아 잡수셨을지라도,기본 선방은 했음\n",
      "아~ 진짜 조금만 더 손 좀 보면 왠만한 상업 영화 못지 않게 퀄리티 쩔게 만들어 질 수 있었는데 아쉽네요 그래도 충분히 재미있었습니다 개인적으로 조금만 더 잔인하게 더 자극적으로 노출씬도 화끈하게 했더라면 어땠을까 하는 국산영화라 많이 아낀 듯 보임\n",
      "평점조절위원회에서 나왔습니다(웃음)김혜선은 @내일이 오면@의 김순정,순정이 역할이 제일이다.팜므파탈로써,그 정도까지 잘해낼 줄은,정말 의외였어...연기20년 한사람에게 요즘 사극에서 벌어지고 있는,그녀에 대한 연기논란은 왠지 코미디의한장면 같음(웃음)\n",
      "사실여부를 떠나,알고왔던 아더와 너무 매칭이 안돼더라.원탁기사중 실제 검술 최고수는 랜슬롯으로 알고 있는데,트리스탄보다 못하고,싸우는 검술은 마치 중국검술 흉내낸거 같은게;; 그리고 란슬롯이 실제는 쌍검였나?너무 매칭이 안대 하튼 ㅋ기네비어역도 미스.\n",
      "진짜 이건 아님ㅋㅋㅋㅋㅋ액션영화좋아해서 액션영화만 다운받아서 꾸준히 본게 벌써 몇년인 사람임 근데 이건 진짴ㅋㅋㅋㅋㅋㅋ아무리 점수 잘 줘도 100점 만점에 10점?ㅡㅡ돈주고봤는데너무아깝다진짜ㅜㅜ그리고대체 왜 13구역 타이틀을 달고나왔는지 모르겠음 실망\n",
      "영화'산업'이라고 하잖는가? 이딴식으로 홍보 해놓고 속여서 팔았다는 게 소비자 입장에서는 짜증난다. 그나마 다행은 아주 싸구려를 상급품으로 속여판 게 아니라는 점. 그래서 1점. 차라리 연상호 감독 작품 처럼 홍보가 됐다면, 그 비슷하게 만이라도 하지\n",
      "화려한 색채때문에 눈이 아프지만 그 나름대로 화려연예계여자욕망에대해 표현해냈던거같다 보는내내 진짜 리리코심정가진 연옌들도 있을거같고..나를한번도보지못하고알지못하는사람들이날어떻게사랑하냐그런대사 나왔을때 소름돋더라 연예인들은 많은사랑받으면서도 참 허전할듯\n",
      "히가시노 게이고의 추리소설이 사랑 받는 이유는, 치밀한 트릭도 크겠지만 사람이 사람을 죽이는 행위에 감성적 정당성을 부여한 탁월한 설득력에 있다. 본 원작은 말 그대로 '헌신적 사랑'이 그 키워드였고, 용의자 x는 거기에 집중해 훌륭히 결을 살려냈다.\n",
      "TV상영종료후 1년뒤에 극장판이 나올정도의 초 대작.TV편의 설정오류 수정과 새로운 씬 추가가 주된 볼거리. 마마마는 어른들을 위한 애니이다.※우측의 리뷰를 보고 애들과 함께 볼려고 한 분들에게는 절대로 애들에게 보여줄 작품이 아니라고 강력히 주장한다\n",
      "써로게이트의 부작용에 대한 자신만의 생각으로 써로게이트를 통해 행복을 누리고 있는 사람들의 권리를 뺒아가는게 정당한것인가? 장애인이나 식물인가.. 혹은 외모컴플렉스가 있는 사람들은 써로게이트통해 행복한 삶을 살고 있었을텐데.. 너무나 이기적인 결말임.\n",
      "정말 미치도록 재미없다. 무슨 80년대 중국 괴기 판타지물 마냥 시대에 뒤떨어진 연출과 분장력과 스토리. 반전 또한 너무 뻔하다. 아니, 솔직히 반전인 줄도 몰랐다. 처음부터 계속 복선이 깔리는데 뭐가 반전인지? 흔하디흔한 미드 반전만도 못한 애들영화\n",
      "초등학생 시절에 접했던 스파이더맨 3부작을 히어로물 매니아가 된 지금 다시 찾았다. 리부트 후 세계관 확장에 신경쓰고 있지만, 독립된 세계관으로써도 깊은 여운과 재미를 줬던 샘레이미 감독과 토비 맥과이어의 스파이더맨 3부작은 정말 최고라 말하고 싶다.\n",
      "예회장의 매력이 걷잡을수 없다. 무간도 시리즈의 다른 작품들과 등장인물이 거의 완전히 다름에도 불구하고 다른 무간도 시리즈와 잘 조화되며, 이 작품만이 주는 매력 또한 상당하다. 한침의 먹방이 정말 압권. 예회장의 카리스마는 대부의 돈 꼴레오네를 연상\n",
      "어차피 무리인 소설 원작을 재현할 생각 말고, 차라리 영화 나름의 각색을 하는게 더 나았겠다. 이건 뭐 그냥 생뚱맞네. 캐릭터 깊이도 없고, 몰입도 안되고, 감독 혼자서만 감정잡고있고, 영상도 작위적. 아예 헛웃음만 나오더라. 트란안훙꺼 이제 안볼거다\n",
      "그저 옛 영화 입니다. 예전의 경향과 문화를 알고 싶으신 분은 보세요. 지금 봐도 괜찮은 고전명작의 공통점은 그 감독들이 현재까지도 활발히 활동한다는 것이죠. 대부 감독은 2000년대 이후로 성공적이지 못합니다. 구성과 전개가 너무 올드하고 지루하죠.\n",
      "미라소르비노 발킬머와 스케이트장에서 여러가지 표정 지어보일때 너무 이쁘고사랑스러웠네요.. 스토리전개에.조금은.투박한느낌이지만.. 처음 비가내릴때.작은 폐가 안에 들어가.같이 눈을.감고 비의 운율을 느낀다... 괜찮은 영화를알게되어 너무 좋은 하루였네요\n",
      "이 죽일놈의 사랑...에 어울리지 않는,이 무슨 거지같은...영화.차라리 공상과학영화로 각색해오든가...딱 국어책을 낭랑히 읽고있는,대배우의 시나리오리딩을 보는듯하다.레드라이트에 이어서,캐스팅만 쩌는 또하나의 졸작.당신의돈과시간을 조금더 소중히 하시라\n",
      "어렸을 때는 지능이 뒤떨어져 이 영화의 전체적인 흐름과 스토리를, 심지어 그 때문에 반전까지 못 느껴서 루즈하게 느껴졌지만, 나이가 들어 영화의 흐름과 반전을 느낄 정도의 약간은 성숙된(?)지능을 가지고 보니 영화의 완성도가 상당히 높다 여기게 되었다\n",
      "히나타 진짜 싫어하는데 영화가 급전개그렇고 더 라스트가 아니라 제목은 히나타의목도리인듯;;내용도 이상하고 작가가 육백화쯤에서 뜬금없이 번외로 히나타 동생내보내더니 극장판때문이였는듯.만화끝날때까지도 러브라인 확실하지않더니ㅋ작가겁나 배신감느껴짐.괜히 본듯\n",
      "현재2013년...퍼시픽림.슈퍼맨.배트맨.어밴져스등...컴퓨터그래픽의 절정을 보여주는 이시점에 컴퓨터그래픽은 제로....이럴수가....탈을쓰고 나오다니....무슨장난하는줄 알았다.1980년대나 나올법한 영화같지도 않은영화.돈주고보긴아까우니무료로보세요.\n",
      "걸작 공포영화마스터피스를 망쳐놓은 감독의 한심한 연출력...감독 존 무어...당신에게 오멘(666)의 저주가 있으리라.능력이 안되면,손대지를 말든가?제가 무슨 알프레드 히치콕이라고,엉뚱한 녀석.가서 다이하드6-본투비 와일드나 찍고있어~임마...(웃음)\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(raw, 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compatible-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 194543\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVVUlEQVR4nO3df7DldX3f8edrWYhtpaYLOzItIZuqGK2SlC4TwaArMg0/RtfQmE2DtEnTIGhik7SVH2oqqSjZTDOO1WgW2sTFzKJowjagKCi4AbKrF22nmRYZO13UCcaVHYpoAlx494/zPXL2cn+cc/fuOefez/Mxc2fO9/P9nu95n3PueX0/5/P9cVJVSJLWvnWTLkCSNB4GviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8rYgkxyZ5w6TrGKckZyZ56cD0tUlevkLrPjfJzyyxzJuWmP/WJC/sbt+W5MRl1vKaJD80MP3bSY5fzro0WQZ+o5JsSXJ7kjuS3JXktYe5yuOAf70StR2OJPeP8eFeDfyTgemju78lJXk0yZ1J7k4yk+T9gyFaVZ+qqo8vsZq3LjazqrZX1VcGals/TG3z+GfA8wbWe1lVfXuZ69IELfcfQKtYkmOA/wKcXlXf6toy2apWzDGTLmBI366qLQBJ1gO/AHwuyelV9d1JFqa1yx5+m9YDfwM81W+o7pTrJH8rye8l+WzXA31nf5kkf5bkPyXZk+RLSS7r2s8BbgB+vLvPC5OsS/Ifu28Qn0vygSRHd8vfnuTt3TeLLyR538Bj/ECSq7vH2tOfl+SUJJ/q6vpckp8c5Qkn+ZWuttuTfCTJc7r2P0jyH7qe9j1Jbhio81lJPpjkz5PcmuTdST7VzXsvvZC+PMkfDDzUG7oa70ny8W7juqiqmq2q64BbgZ/v1v+GJG/vbl+QZG/3vD+W5IQkdwIndM9pW7fcTJJ3da/daUmum/M6nde9H19MclOSjXMfq5s+Mcnt3e0bgHOA9yZ5T9d2e394KMnzk9yc5PPd+/WugdfvnUne073Pf9a9hn9vlPdNK8vAb1BVfQ94PXBdkrckedbA7CuAO6rq1V0P9B8k+alu3onAF6rqFcBPAP8iyQ9V1a3AzwH/vaq2dMMIvwA8UlWvqqqzgL8E/lW3nvXAE1X1k916XjQQTO8B/hp4RVW9oqre0gXIe4GLqurV9IYY3j/st5IkZwEvBF5VVWcDnwIu788GnltVL6+qM4BHgW3dvEt7L1edXlXnAF8HXtS9hr8G/CFwTVX94sDDPdy9dmcA3wUuGKbGzp3AP+5ur+fpb+BXAq+rqrOq6mer6pvde/PN7vX+aLfci4GZqjqzqr44Zx0APwacVVWnAV8CrprnsQ6Zrqqfo7ch+rWqumJwfvfN5I+Bd1fVK4FXAscC/35gXS8BtlTVmcBdwJtHeD20wgz8RlXV/6qq1wH/F7glySndrPOAfm/4TnoBtKmbF+BPuvs/AXwZ+JEFHuI84GcG1vMaehuMvv56CtgH/MOu/bX0AmTwIk8vBP4R8PFuXX8CPAvYMOTTPQ94BXBHd/9LgRMG5t80cHvvQC1n0hv66vsQvRBfzCcHbt8FPH/IGqHbEM7T/jbgXUnOXOL+j1fVTYvM/+DA6/p+4PQRapvPjwJfr6p74Pvv5buBnx5Y5k+rara7PfjaagIcw29cVf1pknuBG4GX0+sEvL4/tj/P8o8PTM6ycKdhHfCrVfWFBeYvtJ50f3PXdW9VnbfgE1ncOuDqqvrYiLX0p4FeoCWZZXFPDdx+gtE+Y+cDn57bWFWfTvJZesNFl1bVzy9w/4eXWP/cHcr9Wgs4aqD97w5R6/fLm6dt8DUY9v9FY+CL36g5Y6kvA/6qu30HcEV/uGTOcM9iHgMG13kH8O8GxnOPTjLM/9sngavnDNd8hd6wz08M1D9sXf1afjXJs7v7rhtmbJ3e0M+b+3UneTO9IYu+uc95WdLbb/JW4CS6bz5z5q/reskfAU5L0g/kx0YcE/+33TAM9IZW+huXr/H0UBLA3MNrF3qe/xs4sT8c171nb6M3zKMpZA+/QV3Y3ZLkKXq9rr8CLulmX0VvvHxfku8Cs0l+qqqeovfBHzTL0z3gbwLfSrIX+H3gg8APA3uTfKdb5vXAge4+Ty6wnsuAq4E/T/I48BdV9aYk/xz4nS5UZultGH5nnqf3VDds0/fHVfW+JC8GPt/VEnqB9xdzHntuLdfRC+G7uu3P54EHBpb9DPDRJOfR22ex2Lrm2pjkc8D36B1Z9El64/Q1z33v6d6rHwCur6pHuvaPdrV9uqp+g8XfnyeAPd1rEHob0V/p5t1J79vDp+ntP7kV+PGB9fw34H1JLga2dut8sqqeTHIBvR2676L3LeFO4HcXeP6LvR4ag3g9fGl+SY4C1nX7K0hyJfA3VfW7i99Tmk728KWFnUivB/8YvXHpe4Dtky1JWj57+JLUCHfaSlIjDHxJasTUjuEff/zxtWnTpkmXIUmryr333vvtqto437ypDfxNmzYxMzMz6TIkaVVJ8sBC8xzSkaRGGPiS1AgDX5IaYeBLUiMMfElqxFBH6SR5HvAOehedehJ4O/Aqej8UMQvsrart3bIXjtIuSRqPJQO/u7Lee4BLq+qhru1Y4CLg3O4a4dcnORl4cJT2qhrnD05LUtOG6eGfRu+n3X6zu574PcA3gNsGLuW6G9hC79Kxo7Qb+JI0JsME/iZ6v0v52qp6LMkH6F1F8GsDyxwEXkDv90APjtB+iO562xcDnHTSSUM/CUnS0oYJ/O8Bt1dV/8cVbgZO4dDfE90APNT9vWSE9kNU1Q5gB8DmzZun+jKemy6/5fu3919z/gQrkaThDHOUzr30fgKv72XAV4GzB36Gbiu9X9PZN2K7JGlMluzhV9WDSW5NcgO9oZn9VfWJ7mfybux+1Hmmqu4DSLJzlHZJ0ngMdVhmVV0LXDunbRewa55lR2qXJI2HJ16tgE2X33LImL4kTSMDX5IaYeBLUiMMfElqhIEvSY2Y2p84nFbunJW0WtnDl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8FeQ19SRNM0MfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgHwEejy9pGhn4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqRHrl1ogyZeBfd3kE8BbqqqSXAhsA2aBvVW1vVt+pHZJ0ngsGfjAQ1V1yWBDkmOBi4Bzu/C/PsnJwIOjtFfV/Sv8fCRJCxhmSGddkquS/Nckr+nazgBuq6rqpncDW5bRfogkFyeZSTJz4MCB5TyfqeIJWJKmyZI9/Ko6CyDJeuBjSe4DjgMODix2EHgB8OiI7XMfawewA2Dz5s01d74kafmG3mlbVbPAZ4EXAw8BGwZmb+jaRm2XJI3JqEfpnA78D3o7cc9Okq59K7BnGe1NcGhH0jQY5iidDwN/DTwbuKmq9nftO4Ebk8wCM1V133LaJUnjMcwY/r9coH0XsOtw2yVJ4+GJV5LUCAN/jBzLlzRJBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMM/AnwaB1Jk2DgS1IjDHxJaoSBL0mNMPAnyLF8SeNk4EtSI4b5TVuBPXFJq549/Cng0I6kcTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBPEY/WkXQkGfiS1AgDX5IaYeBLUiMMfElqhIE/hdx5K+lIGOriaUnWAzuB71TVG5NcCGwDZoG9VbW9W26kdknS+Ax7tcx3AH8I/GySY4GLgHOrqpJcn+Rk4MFR2qvq/pV/OmvLYC9//zXnT7ASSWvBkoHf9c6/CPQD+gzgtqqqbno3sAV4YMR2A1+SxmjRMfwkpwInVNXNA83HAQcHpg92baO2z/d4FyeZSTJz4MCBoZ+EJGlpS+203QacnORDwNXAy4GNwIaBZTYAD3V/o7Q/Q1XtqKrNVbV548aNozyPNc8duZIO16KBX1WXVdUbq+oS4G3A3cCHgbOTpFtsK7AH2DdiuyRpjEb5icNZYLaqHk6yE7gxySwwU1X3AYzaLkkan6EDv6q+AVzS3d4F7JpnmZHaJUnj44lXq4xj+ZKWy8CXpEYY+KuUPX1JozLwJakRBv4qZ09f0rAMfElqhIEvSY0w8NcIh3YkLcXAl6RGGPiS1AgDf41yiEfSXKNcPE2rgCEvaSH28CWpEQa+JDXCwJekRhj4ktQIA1+SGuFROkvwqBdJa4WBv8bN3WDtv+b8CVUiadIc0pGkRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1YqgTr5J8oFv2WOD+qnpnkguBbcAssLeqtnfLjtQuSRqPoQK/qt7cv53kw0l+DLgIOLeqKsn1SU4GHhylvaruX/mnpMX0z7z1jFupPSNdWiHJc4DjgR8Fbquq6mbtBrYAD4zYbuBL0pgMNYaf5PlJ/giYAf4zcBRwcGCRg8Bx3d8o7XMf5+IkM0lmDhw4MMrzkCQtYajAr6qvVtWFwIuAXwKOBjYMLLIBeKj7G6V97uPsqKrNVbV548aNozwPSdISRjpKp6pm6fXu7wDOTpJu1lZgD7BvxHZJ0pgsOYaf5FTgN4BHgb8DfKKqvpZkJ3Bjkllgpqru65YfqV2SNB5LBn5VfQl4wzztu4Bdh9suSRoPT7xq1KbLb1ny17yGWUbS6mHgS1IjDHxJaoS/aatncBhHWpsM/MYZ7lI7HNKRpEYY+JLUCANfkhph4GvZPE5fWl0MfB02g19aHQx8SWqEgS9JjTDwJakRnnilJTk+L60NBv4CDDlJa41DOpLUCANfkhph4EtSIwx8SWqEgS9JjfAonTk8Omf5+q/d/mvOn3AlkuZjD1+SGmHgS1IjHNLpOJQjaa2zhy9JjTDwJakRBr4kNWKoMfwk1wJPARuA3VX1kSQXAtuAWWBvVW3vlh2pXZI0HkMFflX9MkCSdcCeJLuBi4Bzq6qSXJ/kZODBUdqr6v4j8qwkSc8w6pDOMcBDwBnAbVVVXftuYMsy2g+R5OIkM0lmDhw4MGJpkqTFjBr4vwVsB44DDg60H+zaRm0/RFXtqKrNVbV548aNI5YmSVrM0IGf5NeBL1fV3fR6+RsGZm/o2kZtlySNyVCBn+RS4JGq2tU17QPOTpJueiuwZxntkqQxWXKnbZIzgCuAzyQ5vWu+EtgJ3JhkFpipqvu65UdqlySNx5KBX1X3ACfNM2tX9zd3+ZHaJ81LKkhqhSdeSVIjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+Fpxmy6/xcNdpSlk4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGDPWbtmuRhw1Kao09fElqhIEvSY0w8CWpEQa+JDXCwNcR4zV1pOli4EvSETCNHR4DX5Ia0dxx+NO2xZWkcbGHL0mNMPAlqREGviQ1wsCXpEYMtdM2yVHAVcDmqjqna7sQ2AbMAnuravty2rX2De4o33/N+ROsRGrbsD381wC30G0gkhwLXARsraoLgJcmOXnU9pV+MpKkhQ3Vw6+qmwCS9JvOAG6rquqmdwNbgAdGbL//cIqXJA1vuWP4xwEHB6YPdm2jth8iycVJZpLMHDhwYJmlSZLms9zAfwjYMDC9oWsbtf0QVbWjqjZX1eaNGzcuszRNs2k83VxqxXIDfx9wdp4e49kK7FlGuyRpTEa9tMLjAFX1cJKdwI1JZoGZqroPYNR2SdJ4jBT4VXXewO1dwK55lhmpXW3qD+t4mKY0Pp54pYlyTF8aHwNfkhrRzOWR7UVOt7nvj0M9Wq2mOWvs4WsqOdQjrTwDX5IaYeBLUiOaGcPX6uTYvrRyDHytKguN67shkJbmkI4kNcIevtaE+X5kxbN5NU6r4agye/iS1Ah7+Fpz5va0HPeXegx8NcsjgLQSVsNQTp+BL3UW2gD4I+xaK9Z84K+mra+my3z/O0ttFNwgtGM1Zos7baUV5DWANM3WfA9fOpIWCvel9g/4jUCTYOBLYzDshgEcJpp2q/kbnIEvrTIeXTQZqzno+wx8acoMex7BUvd3Q7Ay1kLQ9xn40hqx1IZivg2A3xYWtpaCvs/Al1a5YYNpmOWG/XawVr5FrMVQX4yBL+kZVnIjcrgbj1E2LnOXXWi6VQa+pCNqpUJ2lPUc7n6QtcrAlzQVDOUjzzNtJakRa7KHb09Bkp5prIGf5EJgGzAL7K2q7eN8fElq2diGdJIcC1wEbK2qC4CXJjl5XI8vSa0bZw//DOC2qqpuejewBbh/jDVI0litxKGrK2WcgX8ccHBg+iDwgsEFklwMXNxNPprkK4fxeMcD3z6M+4+Lda6s1VDnaqgRrHMlLVpjfntFH+uHF5oxzsB/CHjJwPSGru37qmoHsGMlHizJTFVtXol1HUnWubJWQ52roUawzpU0LTWO87DMfcDZSdJNbwX2jPHxJalpY+vhV9XDSXYCNyaZBWaq6r5xPb4ktW6sh2VW1S5g15gebkWGhsbAOlfWaqhzNdQI1rmSpqLGPH3QjCRpLfPSCpLUCANfkhqxJq+lM82XcEhyLfAUvcNSd1fVR6ax3iTrgZ3Ad6rqjVNa4/OAdwABngTeDryK6avz3wCnAU8AR9M71+SnmXCdSY4CrgI2V9U5Xdu87/Mk3/8F6nzG52ga6+zaD/ksTbTOqlpTf8CxwK08vX/ieuDkSdc1T53rgLumtV56/7j/FLhuGmukF/IfA46b5vceeA5wy8D0ZfQuMTLxOoHXAacDty/2+k36dZ1b55x564C7puH9X6jOwc/SpOtciz381XIJh2PonXg2dfV2vY8vDtQwdTXS6zF/HfjNJM8G7gG+wfTV+Qjwl0meC/w/4ERgP1NQZ1XdBPD0qTELvs8PLNA+lnrnqXNQ/3MEE/4/na/OeT5LE61zLY7hz3cJh+MmVMtifgvYzpTVm+RU4ISqunmgeapq7Gyid+b2W6vql4BTgZcxZXV2H+oPA78M/CKwFziKKauzs9D7PI3vf1//cwRTVucCnyWYYJ1rsYe/5CUcJi3JrwNfrqq7u97pNNW7DfjBJB+i99XzVOB/cuj/yqRrBPgeva/Oj3XTNwOn0Kutb+J1JjkFOK+qruymXwc8F3j2wGITr7Oz0GdnKj9Tg5+jrmna6nzGZynJm4D/w4TqXIs9/Km+hEOSS4FHqncSGkxZvVV1WVW9saouAd4G3E2vhzo1NXbupdej73sZ8FWmr86/T69H3/c4vQ3TtNUJC/8vTtX/KMz7OYIpq3O+z1JV/d4k61xzPfya4ks4JDkDuAL4TJLTu+Yr6e3Bn7p66R1BMDuNr2lVPZjk1iQ3AI8C+6vqE0mOmaY6gc8Ar0zyR/S+lfxt4C30duJNS52Pw+KfnSl5/x/vapn3c1RV35qmOueY7f4mmlGeaStJjViLQzqSpHkY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakR/x+ENmejDiQ+wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 중복 제거\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    sen = str(sen)\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-thunder",
   "metadata": {},
   "source": [
    "### 데이터 분할\n",
    "너무 긴 문장에 대해서 학습에 방해된다고 판단하여 제거한다. (SentencPiece) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dirty-coffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVJUlEQVR4nO3df7DldX3f8edrAWMbqe3CTpgWybYi/iiipZdGMOiKTANkdA2JIQ3S2togRKXGtiL+SCUBTTbTjGM12oU0AXQWQSNbRVFQcAO46EWaaaZFxpkCZoLJujsM4g/gwrt/fL8Xzl7u7j3n7t1zzt7P8zFzZ873/f3e7/d9vufe9/mc9/d7vt9UFZKk1W/NpBOQJI2HBV+SGmHBl6RGWPAlqREWfElqhAVfkhphwdeKSHJokjdMOo9xSnJykhcPTF+W5OUrtO7Tk/zKEsv85hLz35nk+f3jG5McucxcXpPkOQPTv5/k8OWsS5NlwW9Ukg1Jbkpyc5Jbk7x2H1d5GPDvVyK3fZHknjFu7tXAPx+YPqT/WVKSh5PckuS2JLNJPjJYRKvqi1X16SVW8869zayqTVX17YHcDh4mt0X8MvDcgfVeWFXfX+a6NEHL/QPQASzJM4A/Bk6sqr/tY5lsVivmGZNOYEjfr6oNAEkOBt4IfDXJiVX1w0kmptXLEX6bDgZ+AjwxH6j+K9dJ/k6SP0rylX4E+v75ZZL8eZL/mmRbkm8lubCPnwZcDby0/53nJ1mT5Hf7TxBfTfLRJIf0y9+U5L39J4tvJPnwwDZ+Ksml/ba2zc9LclySL/Z5fTXJz4/yhJO8tc/tpiSfSPLsPv4nSf5LP9K+PcnVA3k+M8nHknw9yQ1JPpDki/28D9EV6Xcl+ZOBTb2hz/H2JJ/u31z3qqrmqupy4Abg1/v1vyHJe/vHZybZ3j/va5IckeQW4Ij+OZ3VLzeb5JJ+352Q5PIF++mM/vX4ZpLrkqxbuK1++sgkN/WPrwZOAz6U5IN97Kb59lCSo5N8PsnX+tfrkoH99/4kH+xf5z/v9+E/GOV108qy4Deoqn4EvB64PMkFSZ45MPsi4OaqenU/Av1HSX6hn3ck8I2qegXwc8C/TvKcqroB+DXgf1XVhr6N8Ebgoap6VVWdAvw18O/69RwMPFZVP9+v54UDhemDwI+BV1TVK6rqgr6AfAg4p6peTddi+Miwn0qSnAI8H3hVVZ0KfBF41/xs4Geq6uVVdRLwMHBWP+/8bnfViVV1GvBd4IX9Pnw78KfA71XVvx3Y3IP9vjsJ+CFw5jA59m4B/ln/+GCe+gT+buB1VXVKVf1qVX2vf22+1+/vT/XLvQiYraqTq+qbC9YB8BLglKo6AfgWcPEi29ptuqp+je6N6O1VddHg/P6TyZ8BH6iqVwKvBA4F/vPAuo4FNlTVycCtwFtG2B9aYRb8RlXV/6mq1wH/D7g+yXH9rDOA+dHwLXQFaH0/L8Bn+99/DLgL+Md72MQZwK8MrOc1dG8Y8+bXU8AdwD/p46+lKyCDF3l6PvBPgU/36/os8Exg7ZBP9wzgFcDN/e+fDxwxMP+6gcfbB3I5ma71Ne/jdEV8b74w8PhW4Oghc4T+jXCR+HuAS5KcvMTvP1pV1+1l/scG9utHgBNHyG0xLwC+W1W3w5Ov5QeAXxpY5nNVNdc/Hty3mgB7+I2rqs8luRO4Fng53SDg9fO9/UWWf3Rgco49DxrWAG+rqm/sYf6e1pP+Z+G67qyqM/b4RPZuDXBpVV0zYi7z00BX0JLMsXdPDDx+jNH+x34R+NLCYFV9KclX6NpF51fVr+/h9x9cYv0LDyjP51rAQQPxvzdErk+mt0hscB8M+/eiMXDnN2pBL/VlwN/0j28GLppvlyxo9+zNI8DgOm8G/tNAP/eQJMP8vX0BuHRBu+bbdG2fnxvIf9i85nN5W5Jn9b+7ZpjeOl3r5y3zeSd5C13LYt7C57ws6Y6bvBM4iv6Tz4L5a/pR8ieAE5LMF+RHRuyJ/8e+DQNda2X+zeV+nmolASw8vXZPz/P/AkfOt+P61+w9dG0eTSFH+A3qi931SZ6gG3X9DXBeP/tiun75HUl+CMwl+YWqeoLuH3/QHE+NgL8H/G2S7cB/Bz4G/CywPckP+mVeD+zof+fxPaznQuBS4OtJHgX+sqp+M8m/Av6gLypzdG8Mf7DI03uib9vM+7Oq+nCSFwFf63MJXcH7ywXbXpjL5XRF+Nb+/edrwH0Dy34Z+FSSM+iOWextXQutS/JV4Ed0ZxZ9ga5PX4v87u39a/VTwFVV9VAf/1Sf25eq6h3s/fV5DNjW74PQvYm+tZ93C92nhy/RHT+5AXjpwHr+J/DhJOcCG/t1Pl5Vjyc5k+6A7iV0nxJuAf5wD89/b/tDYxCvhy8tLslBwJr+eAVJ3g38pKr+cO+/KU0nR/jSnh1JN4J/hK4vfTuwabIpScvnCF+SGuFBW0lqhAVfkhoxtT38ww8/vNavXz/pNCTpgHLnnXd+v6rWLTZvagv++vXrmZ2dnXQaknRASXLfnubZ0pGkRljwJakRFnxJaoQFX5IaYcGXpEYMdZZOkucC76O76NTjwHuBV9HdKGIO2F5Vm/plzx4lLkkajyULfn9lvQ8C51fVzj52KHAOcHp/jfCrkhwDPDBKvKrGecNpSWraMCP8E+hu7fbb/fXEbwf+Crhx4FKuW4ENdJeOHSVuwZekMRmm4K+nuy/la6vqkSQfpbuK4P0Dy+wCnkd3P9BdI8R3019v+1yAo446augnIUla2jAF/0fATVU1f3OFzwPHsfv9RNcCO/ufY0eI76aqNgObAWZmZpq7jOf6d12/2/S9v/eLE8pE0mo0zFk6d9LdAm/ey4DvAKcO3IZuI93ddO4YMS5JGpMlR/hV9UCSG5JcTdeaubeqPtPfJu/a/qbOs1V1N0CSK0eJS5LGY6jTMqvqMuCyBbEtwJZFlh0pLkkaj6m9Wqbs6UtaWX7TVpIaYcGXpEZY8CWpERZ8SWqEB20naOFBWUnanxzhS1IjLPiS1AgLviQ1woIvSY2w4EtSIyz4ktQIT8s8gAyexul1dSSNyhG+JDXCgi9JjbDgS1IjLPiS1AgLviQ1woIvSY2w4EtSIzwP/wDl/W4ljcoRviQ1woIvSY2w4EtSIyz4ktQIC74kNcKCL0mNWPK0zCR3AXf0k48BF1RVJTkbOAuYA7ZX1aZ++ZHikqTxGOY8/J1Vdd5gIMmhwDnA6X3xvyrJMcADo8Sr6p4Vfj6SpD0YpuCvSXIx8Bzgs1X1OeAk4Maqqn6ZrcAG4L4R47sV/CTnAucCHHXUUct7Ro3yi1iSlrJkwa+qUwCSHAxck+Ru4DBg18Biu4DnAQ+PGF+4rc3AZoCZmZlaOF+StHxDH7StqjngK8CLgJ3A2oHZa/vYqHFJ0piMepbOicBf0B3EPTVJ+vhGYNsy4tpP1r/r+t1+JGmYs3SuAH4MPAu4rqru7eNXAtcmmQNmq+ru5cQlSeMxTA//3+whvgXYsq9xSdJ4+MUrSWqE18NvhKdtSnKEL0mNsOBLUiMs+JLUCAu+JDXCgi9JjfAsnUZ51o7UHkf4ktQIC74kNcKCL0mNsIcvYPeevv18aXVyhC9JjXCEP0Zel17SJFnw9TSesimtTrZ0JKkRFnxJaoQFX5IaYcGXpEZY8CWpEZ6loyV51o60OjjCl6RGWPAlqREWfElqhAVfkhrhQVuNzIO40oFpqIKf5GDgSuAHVfXmJGcDZwFzwPaq2tQvN1JckjQ+w47w3wf8KfCrSQ4FzgFOr6pKclWSY4AHRolX1T0r/3Q0CY74pQPDkgW/H51/E5gv0CcBN1ZV9dNbgQ3AfSPGLfiSNEZ7PWib5HjgiKr6/ED4MGDXwPSuPjZqfLHtnZtkNsnsjh07hn4SkqSlLTXCPwv4+0k+DhwKHA/87wW/txbY2f8cO0L8aapqM7AZYGZmphZbRtPP2yVK02mvI/yqurCq3lxV5wHvAW4DrgBOTZJ+sY3ANuCOEeOSpDEa5bTMOWCuqh5MciVwbZI5YLaq7gYYNS5JGp+hC35V/RVwXv94C7BlkWVGikuSxscvXmm/8pRNaXp4aQVJaoQjfI2VI35pchzhS1IjHOFrohzxS+PjCF+SGmHBl6RG2NLRVLHFI+0/jvAlqREWfElqhC0dHTBs90j7xoKvqbawyEtaPls6ktQIC74kNcKCL0mNsOBLUiMs+JLUCM/S2c88y0TStLDg64C11Jup5+lLu7OlI0mNsOBLUiMs+JLUCAu+JDXCgi9JjbDgS1IjLPiS1AgLviQ1YqgvXiX5aL/socA9VfX+JGcDZwFzwPaq2tQvO1JckjQeQxX8qnrL/OMkVyR5CXAOcHpVVZKrkhwDPDBKvKruWfmnJHW8Q5a0u5EurZDk2cDhwAuAG6uq+llbgQ3AfSPGLfiSNCZD9fCTHJ3kk8As8N+Ag4BdA4vsAg7rf0aJL9zOuUlmk8zu2LFjlOchSVrCUAW/qr5TVWcDLwTeBBwCrB1YZC2ws/8ZJb5wO5uraqaqZtatWzfK85AkLWGks3Sqao5udH8zcGqS9LM2AtuAO0aMS5LGZMkefpLjgXcADwM/DXymqu5PciVwbZI5YLaq7u6XHykuSRqPJQt+VX0LeMMi8S3Aln2NS5LGwxugqBmDp2mOeoqmp3hqNfCbtpLUCAu+JDXClo60CG8+r9XIgq8mWdDVIls6ktQIC74kNcKCL0mNsIcv7Weew69pYcGXxsw3AE2KLR1JaoQFX5IaYcGXpEbYw5eWwS9u6UBkwV9hFgJJ08qWjiQ1woIvSY2w4EtSIyz4ktQIC74kNcKzdPaRZ+VoX+3LvXalUTjCl6RGWPAlqRG2dEZkC0fSgcoRviQ1woIvSY2w4EtSI4bq4Se5DHgCWAtsrapPJDkbOAuYA7ZX1aZ+2ZHikqTxGKrgV9VvACRZA2xLshU4Bzi9qirJVUmOAR4YJV5V9+yXZyVJeppRWzrPAHYCJwE3VlX18a3AhmXEd5Pk3CSzSWZ37NgxYmqSpL0ZteD/DrAJOAzYNRDf1cdGje+mqjZX1UxVzaxbt27E1CRJezN0wU/yW8BdVXUb3Sh/7cDstX1s1LgkaUyGKvhJzgceqqotfegO4NQk6ac3AtuWEZckjcmSB22TnARcBHw5yYl9+N3AlcC1SeaA2aq6u19+pLgkaTyWLPhVdTtw1CKztvQ/C5cfKT7tvJSCpNXCL15JUiMs+JLUCAu+JDXCgi9JjbDgS1IjLPiS1AjveCVNkYWnAXtTc60kR/iS1AgLviQ1woIvSY2w4EtSIyz4ktQIC74kNcLTMhfhFTIlrUaO8CWpERZ8SWqEBV+SGmHBl6RGeNBWmmJeW0cryRG+JDXCgi9JjbClg+fdS2qDI3xJaoQFX5IaYcGXpEZY8CWpEUMdtE1yEHAxMFNVp/Wxs4GzgDlge1VtWk5c0vA8L1/7YtgR/muA6+nfIJIcCpwDbKyqM4EXJzlm1PhKPxlJ0p4NNcKvqusAksyHTgJurKrqp7cCG4D7Rozfsy/JS5KGt9we/mHAroHpXX1s1PhukpybZDbJ7I4dO5aZmiRpMcv94tVO4NiB6bV9bNT4bqpqM7AZYGZmphbOl7Q7e/oaxXJH+HcAp+apHs9GYNsy4pKkMRl1hP8oQFU9mORK4Nokc8BsVd0NMGpckjQeeeo46nSZmZmp2dnZsWzLa+loNbK906Ykd1bVzGLzvHiatErZ39dCftNWkhrR5AjfFo5atNTfvZ8AVr8mC76kp7MFtPrZ0pGkRljwJakRtnQkLWpvPX/bPQcmC76kkY164oNvENPBlo4kNcIRvqT9bvATwcLRvmcHjY8jfElqhCN8SWO1VP/f4wP7jwVf0gHNs4mGZ8GXtGqNejmJvR1rWA2auDyy186RtNKm9eCzl0eWpDGbxk8LFnxJWoZROgfTcqVST8uUpEZY8CWpERZ8SWqEBV+SGmHBl6RGWPAlqREWfElqhAVfkhphwZekRqzKb9p67RxJerqxFvwkZwNnAXPA9qraNM7tS1LLxtbSSXIocA6wsarOBF6c5JhxbV+SWjfOHv5JwI311PWYtwIbxrh9SWraOFs6hwG7BqZ3Ac8bXCDJucC5/eTDSb69j9s8HPj+Pq5jfzCv0UxrXjC9uZnXaCaaV35/j7OWk9fP7mnGOAv+TuDYgem1fexJVbUZ2LxSG0wyu6cbAUySeY1mWvOC6c3NvEbTSl7jbOncAZyaJP30RmDbGLcvSU0b2wi/qh5MciVwbZI5YLaq7h7X9iWpdWM9LbOqtgBbxrjJFWsPrTDzGs205gXTm5t5jaaJvKb2JuaSpJXlpRUkqREWfElqxKq8lg5M12UckhwEXAzMVNVp05JfksuAJ+hOkd1aVZ+Ykrw+Sve3eShwT1W9fxry6nM7GLgS+EFVvXka8kpyF91ZcACPARdUVU06tyTPBd4HBHgceC/wqgnn9ALg7QOhE+m++3P0JPPqc/sPwAl0r+EhfV6/tKJ5VdWq+6ErFDfw1DGKq4BjJpjP6+j+sG6a0vzWALdOW159DlcAL5mWvOjeuP8lcPm07K/5v6sFsYnmRlfkrwEOm5acFsnxIOD6acgLeDZw/cD0hXSXolnRvFZrS2eqLuNQVddV1dcHQlOVH/AMui/BTVVeSZ5N903DF0xDXv2I+ZvAPX1oWvbXmiQXJ/kfSV4zJbmdAHwX+O0kf5zkTVOQ00K/DFzHdOT1EPDXSX4myTOBI4FHVzqv1drSWfIyDhM2bfn9DrCJ7ivZE88rydF0I+l/AbyNruU00bySHA8cUVWfTLK+D0/F61hVp8CT7aZrktw9Bbmtp/tm/Wur6pG+TXckcP8Ec1rojcCZ/c9EX8eqqiRXAL9BN/jaTvcJZEXzWq0j/J10RWLe0y7jMGFTk1+S3wLuqqrbpiWvqvpOVZ0NvBB4E10/c9J5nQUck+TjwKXAy4F1U5DXk6pqDvgK8CIm/1r+iK7V9Eg//XngJxPO6UlJTgW+XlU/YfL7iiTHAWdU1SVV9THgh3StphXNa7UW/Gm/jMNU5JfkfOCh6r4QNzV5zesL2EHAzZPOq6ourKo3V9V5wHuA2+iOL0zN/uqdCPwFk38t7wReNjD9MuA7E85p0FuBP+ofT3pfAfxDur/1eY8Cx610XquypVPTexmHR2E68ktyEnAR8OUkJ/bhd9OdgTLJvI4H3gE8DPw08Jmqun/S+2uBOWBuGl5HgL4V8GPgWcB1VXVvH59YblX1QJIbklxN91reW1WfSfKMSeU0L8lLgfuramef6zS8jl8GXpnkk3Sfjv4ucAHdCQIrlpfftJWkRqzWlo4kaQELviQ1woIvSY2w4EtSIyz4ktQIC74kNcKCL0mN+P9gzjaJqS1P+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 80\n",
    "min_len = 0\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-yahoo",
   "metadata": {},
   "source": [
    "## 3. SentencePiece 학습\n",
    "SentencePiece의 vocab_size를 10,000과 5,000으로    \n",
    "model_type을 unigram과 bpe로 하여 4가지를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "architectural-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 414127  4월  6 17:20 korean_spm_10k.model\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 185330  4월  6 17:20 korean_spm_10k.vocab\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 317147  4월  6 17:22 korean_spm_5k.model\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28  83900  4월  6 17:22 korean_spm_5k.vocab\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 408235  4월  6 17:21 korean_spm_bpe_10k.model\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 149445  4월  6 17:21 korean_spm_bpe_10k.vocab\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 314970  4월  6 17:22 korean_spm_bpe_5k.model\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28  66181  4월  6 17:22 korean_spm_bpe_5k.vocab\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 414123  4월  6 16:11 korean_spm.model\r\n",
      "-rw-rw-r-- 1 aiffel-dj28 aiffel-dj28 185330  4월  6 16:11 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_10k --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_type=bpe --model_prefix=korean_spm_bpe_10k --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_5k --vocab_size={}'.format(temp_file, vocab_size // 2)    \n",
    ")\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_type=bpe --model_prefix=korean_spm_bpe_5k --vocab_size={}'.format(temp_file, vocab_size // 2)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stock-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1843, 10, 436, 15, 1348, 10, 174, 16, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm_10k.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-former",
   "metadata": {},
   "source": [
    "## 4. 모델 성능 분석\n",
    "SentencePiece의 성능을 분석하기 위해서 간단한 LSTM 모델을 사용한다.   \n",
    "4가지의 SentencePiece와 Mecab을 비교 분석해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-profession",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "모델에 학습하기 위해서 데이터를 모델에 넣을 수 있게 변환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opponent-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre',maxlen=80)\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "provincial-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0  490 3218   14 1234 2038    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  1540 2051  215  649   10    3   17 9939 1016    7]]\n"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "russian-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.Load('korean_spm.model')\n",
    "train_test, word_index, index_word = sp_tokenize(s, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "statistical-classic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195339, 80)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comparable-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96182, 80)\n",
      "(96182,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "X_train = train_test[:146182]\n",
    "X_test = train_test[146182:]\n",
    "\n",
    "y_train = np.array(list(train_data['label']))\n",
    "y_test = np.array(list(test_data['label']))\n",
    "\n",
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-relative",
   "metadata": {},
   "source": [
    "### 모델 만들기\n",
    "토크나이저의 성능을 비교하기 위해서 간단한 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ignored-membership",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,322,821\n",
      "Trainable params: 2,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다.\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수\n",
    "\n",
    "# model 설계\n",
    "model1 = keras.Sequential()\n",
    "model1.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model1.add(keras.layers.LSTM(word_vector_dim))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model1.add(keras.layers.Dense(10, activation='relu'))\n",
    "model1.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-comfort",
   "metadata": {},
   "source": [
    "### 모델 훈련 및 성능 평가\n",
    "각각의 토크나이저 모델에 대해서 학습을 시키고 성능을 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ahead-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 17s 93ms/step - loss: 0.4361 - accuracy: 0.7929 - val_loss: 0.3432 - val_accuracy: 0.8507\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.3130 - accuracy: 0.8668 - val_loss: 0.3320 - val_accuracy: 0.8541\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 16s 87ms/step - loss: 0.2744 - accuracy: 0.8824 - val_loss: 0.3388 - val_accuracy: 0.8540\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 17s 89ms/step - loss: 0.2384 - accuracy: 0.8979 - val_loss: 0.3594 - val_accuracy: 0.8507\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 17s 91ms/step - loss: 0.2029 - accuracy: 0.9118 - val_loss: 0.3956 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history1 = model1.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "executed-ivory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 10s - loss: 0.4058 - accuracy: 0.8437\n",
      "[0.4057556092739105, 0.8437455296516418]\n"
     ]
    }
   ],
   "source": [
    "results = model1.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "registered-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(spms, vocab):\n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.load(spms)\n",
    "    train_test, word_index, index_word = sp_tokenize(s, raw)\n",
    "    X_train = train_test[:146182]\n",
    "    X_test = train_test[146182:]\n",
    "\n",
    "    y_train = np.array(list(train_data['label']))\n",
    "    y_test = np.array(list(test_data['label']))\n",
    "\n",
    "    # validation set 50000건 분리\n",
    "    x_val = X_train[:50000]   \n",
    "    y_val = y_train[:50000]\n",
    "\n",
    "    # validation set을 제외한 나머지 \n",
    "    partial_X_train = X_train[50000:]  \n",
    "    partial_y_train = y_train[50000:]\n",
    "    \n",
    "    vocab_size = vocab    # 어휘 사전의 크기입니다.\n",
    "    word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "    # model 설계\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model.add(keras.layers.LSTM(word_vector_dim))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "    model.add(keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    print(results)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "french-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,322,821\n",
      "Trainable params: 1,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 15s 82ms/step - loss: 0.4484 - accuracy: 0.7875 - val_loss: 0.3537 - val_accuracy: 0.8451\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 0.3383 - accuracy: 0.8526 - val_loss: 0.3399 - val_accuracy: 0.8516\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.3094 - accuracy: 0.8641 - val_loss: 0.3346 - val_accuracy: 0.8529\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.2847 - accuracy: 0.8754 - val_loss: 0.3395 - val_accuracy: 0.8536\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.2629 - accuracy: 0.8859 - val_loss: 0.3433 - val_accuracy: 0.8520\n",
      "1537/1537 - 8s - loss: 0.3510 - accuracy: 0.8485\n",
      "[0.3509661555290222, 0.8484854698181152]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 200)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,322,821\n",
      "Trainable params: 1,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.4423 - accuracy: 0.7920 - val_loss: 0.3579 - val_accuracy: 0.8414\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.3388 - accuracy: 0.8524 - val_loss: 0.3416 - val_accuracy: 0.8498\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.3089 - accuracy: 0.8650 - val_loss: 0.3379 - val_accuracy: 0.8535\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.2818 - accuracy: 0.8770 - val_loss: 0.3439 - val_accuracy: 0.8522\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.2593 - accuracy: 0.8873 - val_loss: 0.3499 - val_accuracy: 0.8489\n",
      "1537/1537 - 8s - loss: 0.3570 - accuracy: 0.8446\n",
      "[0.3570345342159271, 0.8445796370506287]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,322,821\n",
      "Trainable params: 2,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.4244 - accuracy: 0.8020 - val_loss: 0.3480 - val_accuracy: 0.8491\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.3126 - accuracy: 0.8662 - val_loss: 0.3342 - val_accuracy: 0.8537\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.2725 - accuracy: 0.8828 - val_loss: 0.3396 - val_accuracy: 0.8553\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.2348 - accuracy: 0.8979 - val_loss: 0.3500 - val_accuracy: 0.8510\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 0.2001 - accuracy: 0.9130 - val_loss: 0.3927 - val_accuracy: 0.8462\n",
      "1537/1537 - 9s - loss: 0.4052 - accuracy: 0.8422\n",
      "[0.40515393018722534, 0.8422198295593262]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f708da9cb90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline('korean_spm_5k.model',5000)\n",
    "pipeline('korean_spm_bpe_5k.model',5000)\n",
    "pipeline('korean_spm_bpe_10k.model',10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-scene",
   "metadata": {},
   "source": [
    "### Mecab 모델\n",
    "Mecab에 대해서도 진행을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "skilled-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using konlpy\n",
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "#미리 정의한 불용어\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다'] \n",
    "num_words = 10000\n",
    "\n",
    "# 함수 기능\n",
    "# 데이터의 중복 제거   \n",
    "# NaN 결측치 제거   \n",
    "# 한국어 토크나이저로 토큰화   \n",
    "# 불용어(Stopwords) 제거   \n",
    "# 사전word_to_index 구성   \n",
    "# 텍스트 스트링을 사전 인덱스 스트링으로 변환   \n",
    "# X_train, y_train, X_test, y_test, word_to_index 리턴   \n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    # 중복, 결측치 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    # 사전 구성\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "    # 변환 text to index\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "attempted-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index to text 사전\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tracked-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "representative-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96938143432699\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571939469296\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2*표준편차)로 한다  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "indirect-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 추가 (using keras.preprocessing.sequence.pad_sequences)\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "promising-completion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,322,417\n",
      "Trainable params: 2,322,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(word_vector_dim))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sufficient-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96182, 41)\n",
      "(96182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "constitutional-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.3506 - val_accuracy: 0.8488\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.3241 - accuracy: 0.8612 - val_loss: 0.3405 - val_accuracy: 0.8501\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.2897 - accuracy: 0.8764 - val_loss: 0.3427 - val_accuracy: 0.8538\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.2556 - accuracy: 0.8923 - val_loss: 0.3500 - val_accuracy: 0.8548\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.2274 - accuracy: 0.9047 - val_loss: 0.3656 - val_accuracy: 0.8536\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "generic-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 7s - loss: 0.3730 - accuracy: 0.8486\n",
      "[0.373012900352478, 0.848587155342102]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-electricity",
   "metadata": {},
   "source": [
    "### 정리\n",
    "위에서 나온 것들을 정리하면 다음과 같다.\n",
    "먼저 Mecab의 경우 test acc: 0.848, val acc: 0.853   \n",
    "SentencePiece의 경우   \n",
    "vocab size = 10,000, model = unigram: test acc: 0.843, val acc: 0.846   \n",
    "vocab size = 5,000, model = unigram: test acc: 0.848, val acc: 0.852   \n",
    "vocab size = 5,000, model = bpe: test acc: 0.844, val acc: 0.848   \n",
    "vocab size = 10,000, model = bpe: test acc: 0.842, val acc: 0.846   \n",
    "이다.\n",
    "정리하면 bpe 보다 unigram이 더 좋은 성능을 보였고,   \n",
    "큰 어휘(10,000)보다 작은 어휘(5,000)가 더 좋은 성능을 보였다.   \n",
    "그리고 sentencePiece보다는 Mecab이 좀 더 좋은 성능을 보였다.   \n",
    "그러나 유의미한 차이를 보인 것 같지는 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-april",
   "metadata": {},
   "source": [
    "## 회고 및 루브릭 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-novelty",
   "metadata": {},
   "source": [
    "### 루브릭 평가 항목\n",
    "1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?\n",
    "\t(코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?)\n",
    "2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?\n",
    "\t(SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.)\n",
    "3. SentencePiece의 성능을 다각도로 비교분석하였는가?\n",
    "\t(SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-system",
   "metadata": {},
   "source": [
    "### 평가 항목에 대한 수행\n",
    "1. SentencePiece를 이용하여 모델을 만들기 과정을 정상적으로 진행을 했다. \n",
    "2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 80% 이상의 정확도를 얻었다.\n",
    "3. SentencePiece의 여러 가지 옵션을 사용하여 비교 분석하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-synthetic",
   "metadata": {},
   "source": [
    "### 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-alfred",
   "metadata": {},
   "source": [
    "노션에 공지된 꼭 포함이 되어야 할 점\n",
    "- 이번 프로젝트에서 **어려웠던 점,**\n",
    "- 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n",
    "- 루브릭 평가 지표를 맞추기 위해 **시도한 것들**.\n",
    "- 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**.\n",
    "- **자기 다짐**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-wells",
   "metadata": {},
   "source": [
    "---\n",
    "- **어려웠던 점**    \n",
    "크게 없었던 것 같다.\n",
    "\n",
    "---\n",
    "- **알아낸 점**    \n",
    "SentencePiece 사용법에 대해서 배울 수 있었다.\n",
    "\n",
    "- **모호한 점**    \n",
    "SentencePiece의 옵션 변경이나 다른 토크나이저를 사용해도 크게 성능이 차이가 나지 않는데 그 이유가 좀 모호하다.\n",
    "\n",
    "---\n",
    "- **시도한 것들**   \n",
    "SetencePiece에 여러 가지 옵션을 바꾸어 실험을 하였다.\n",
    "\n",
    "---\n",
    "- **루브릭 평가 관련 지표**   \n",
    "제 예상에는 모두 달성되었다고 생각한다. 그 이유는 위에 있는 **평가 항목에 대한 수행**에 나와있다.  \n",
    "- **자기 다짐** 및 **나의 생각들**      \n",
    "Going deeper 노드라서 좀 더 어려운 것들이 나올 줄 알았는데 생각보다 쉬웠다. 내가 느끼기에는 저번 E 노드와 큰 차이가 없었던 것 같다. 그래도 점점 갈수록 어려워진다고 해서 기대를 하고 있다. 어쨌든 이전에 nlp를 혼자 공부를 했던 것이 다시 나오니까 다시 복습하는 느낌이 들었다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-cooling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
